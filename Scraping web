# importation des packages

import warnings
warnings.filterwarnings("ignore")

import selenium
from time import sleep
from selenium import webdriver
from selenium.webdriver.common.keys import Keys

import pandas as pd
import re
import numpy as np
from selenium.webdriver.common.by import By



options = webdriver.ChromeOptions()

#options.add_argument('-headlesss')
#options.add_argument('-no-sandbox')
#options.add_argument('-desable-dev-shm-usage')

driver = webdriver.Chrome()

driver.get("https://fr.trustpilot.com/review/veepee.com")

bouton_rejet_cookies = driver.find_element(by='id', value="onetrust-reject-all-handler")

bouton_rejet_cookies.click()

# attendre 3 seconde
sleep(3)





j = 0
df =pd.DataFrame(columns=['nom_client', 
                         'note_avis', 
                         'date_achat', 
                         'date_avis',
                         'nbr_avis',
                         'text_avis',
                         'pays', 
                         'titre_avis'])

for k in range(210):

    # mettre pour chaque varibale une liste de webelemnts qui regroupera les 20 résultats par page
    
    nom_client  = driver.find_elements(By.XPATH,
                                    '//span[@class="typography_heading-xxs__QKBS8 typography_appearance-default__AAY17"]')
#-----------------------------------------------------------

    note_avis   = driver.find_elements(By.CLASS_NAME, 
                             'styles_reviewHeader__iU9Px')

# ----------------------------------------------------

    date_avis = driver.find_elements(By.TAG_NAME,'time')


# -------------------------------------------------------------------

    date_achat  = driver.find_elements(By.XPATH, 
                                          '//p[@class="typography_body-m__xgxZ_ typography_appearance-default__AAY17 typography_color-black__5LYEn"]')
# ---------------------------------------------------------

    nbr_avis = nombre_avis = driver.find_elements(By.XPATH, 
                                  '//div[@class="styles_consumerExtraDetails__fxS4S"]')
#-------------------------------------------------------------

    text_avis   = driver.find_elements(By.XPATH,
                                '//p[@class="typography_body-l__KUYFJ typography_appearance-default__AAY17 typography_color-black__5LYEn"]')

# --------------------------------------------------------------

    pays = driver.find_elements(By.XPATH,
                           '//div[@class="typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l styles_detailsIcon__Fo_ua"]/span')

# ---------------------------------------------------------------

    titre_avis = driver.find_elements(By.XPATH,
                                    '//h2[@class="typography_heading-s__f7029 typography_appearance-default__AAY17"]')

# ***************************************************************

    # remlir le data frame avec les infos récupérées
    
    l = len(text_avis)
    
    for i in range(l):
        
        df.loc[j,'nom_client']  = nom_client[i].text
        
        df.loc[j, 'note_avis']  = note_avis[i].get_attribute('data-service-review-rating')   # Extraire unqiuement le rating review
        
        df.loc[j, 'date_achat'] = date_achat[i]       # récuprer la ligne complète de date, ensuite, extraite uniquement la date
        
        df.loc[j, 'date_achat'] = date_achat[i].text[20:]
        
        df.loc[j, 'date_avis']  = date_avis[i].get_attribute('datetime')[:10]  #Checher la ligne datetime, esnuite extraite la date

        df.loc[j, 'nbr_avis']   = nbr_avis[i].get_attribute('data-consumer-reviews-count')
       
        df.loc[j, 'text_avis']  = text_avis[i].text
        
        df.loc[j, 'pays']       = pays[i].text
        
        df.loc[j, 'titre_avis'] = titre_avis[i].text

        j = j+1

# ***************************************************************
    # passer pà ma page suivante
    page_suivante = driver.find_element(By.NAME,'pagination-button-next')
    
    driver.execute_script("arguments[0].click();", page_suivante)
    
    # patienter 2 secondes pour que la page se charge correctement
    sleep(2)    


df.to_csv('scrap veepee trustpilot 27fev_ 4074_avis.csv', index=False)



