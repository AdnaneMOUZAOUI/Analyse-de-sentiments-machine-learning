{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdnaneMOUZAOUI/Analyse-de-sentiments-machine-learning/blob/Reviews-Analysis/Pr%C3%A9paration_extraction_des_commentaires_uniquement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6AhC9m8Qzys"
      },
      "outputs": [],
      "source": [
        "# Importer le fichier depuis le drive\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('showroom_trustpilot_168897_07 mars.csv')\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.feature_selection import VarianceThreshold, SelectKBest, SelectFromModel, f_regression, mutual_info_regression, RFE, RFECV\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fdw6-4oiQzyu"
      },
      "outputs": [],
      "source": [
        "df=df.rename(columns={\"nom_client\":\"client\",\"date_achat\":\"date_commande\",\"date_avis\":\"date\",\"text_avis\":\"Commentaire\",\"titre_avis\":\"Titre\",\"note_avis\":\"star\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYDNY1xQQzyv",
        "outputId": "00fc392b-8594-440e-c1cc-31fc81a79765"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████| 168897/168897 [00:51<00:00, 3258.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20 mots les plus communs :\n",
            "commande 56221\n",
            "livraison 48559\n",
            "très 42398\n",
            "bien 25659\n",
            "colis 25619\n",
            "site 24226\n",
            "plus 23735\n",
            "produits 21646\n",
            "produit 21337\n",
            "article 18585\n",
            "qualité 16756\n",
            "tout 16474\n",
            "bon 16045\n",
            "reçu 15087\n",
            "délais 13681\n",
            "prix 13328\n",
            "trop 12925\n",
            "long 12839\n",
            "toujours 12055\n",
            "peu 11873\n",
            "\n",
            " 20 2-ngrams les plus communs :\n",
            "('délai', 'livraison') 5899\n",
            "('très', 'bien') 5658\n",
            "('délais', 'livraison') 5497\n",
            "('trop', 'long') 4766\n",
            "('service', 'client') 4570\n",
            "('point', 'relais') 4465\n",
            "('très', 'bon') 4103\n",
            "('bonne', 'qualité') 3820\n",
            "('frais', 'port') 3758\n",
            "('très', 'satisfaite') 3511\n",
            "('peu', 'long') 3466\n",
            "('rien', 'dire') 3240\n",
            "('date', 'lexpérience') 2935\n",
            "('livraison', 'trop') 2910\n",
            "('livraison', 'peu') 2832\n",
            "('bien', 'passé') 2613\n",
            "('produit', 'conforme') 2447\n",
            "('bon', 'site') 2418\n",
            "('cette', 'commande') 2320\n",
            "('bon', 'produit') 2301\n",
            "\n",
            " 20 3-ngrams les plus communs :\n",
            "('livraison', 'trop', 'long') 1587\n",
            "('livraison', 'peu', 'long') 1364\n",
            "('très', 'bon', 'site') 1334\n",
            "('tout', 'bien', 'passé') 1221\n",
            "('rapport', 'qualité', 'prix') 1131\n",
            "('très', 'bonne', 'qualité') 1120\n",
            "('tout', 'très', 'bien') 926\n",
            "('très', 'bien', 'passé') 899\n",
            "('beaucoup', 'trop', 'long') 848\n",
            "('délai', 'livraison', 'peu') 804\n",
            "('délai', 'livraison', 'respecté') 778\n",
            "('très', 'bon', 'produit') 760\n",
            "('livraison', 'peu', 'longue') 745\n",
            "('délai', 'livraison', 'trop') 743\n",
            "('livraison', 'trop', 'longue') 711\n",
            "('livraison', 'beaucoup', 'trop') 705\n",
            "('entre', 'commande', 'livraison') 690\n",
            "('bon', 'rapport', 'qualité') 684\n",
            "('délais', 'livraison', 'trop') 677\n",
            "('plus', 'dun', 'mois') 614\n"
          ]
        }
      ],
      "source": [
        "# Comptage et transformation des commentaires\n",
        "\n",
        "from collections import Counter\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk import ngrams\n",
        "from tqdm import tqdm\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "commentaires = pd.Series(df['Commentaire'])\n",
        "stop_words = set(stopwords.words('french'))\n",
        "stop_words.update(['a', \"jai\", \"cest\", \"sest\", \"car\", \"donc\"])\n",
        "\n",
        "def clean_text(text):\n",
        "    text = \" \".join(text.split()) # supprimer les espaces superflus\n",
        "    text = text.lower() # mettre les mots en minuscule\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation)) # retirer les ponctuations\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    return len(text.split())\n",
        "\n",
        "# Calculer la longueur de chaque commentaire\n",
        "df['longueur'] = commentaires.apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
        "\n",
        "# Calculer le nombre de majuscules dans chaque commentaire\n",
        "df['majuscule'] = commentaires.apply(lambda x: sum(1 for c in x if c.isupper()) if isinstance(x, str) else 0)\n",
        "\n",
        "# Calculer le nombre de points d'exclamation et d'interrogation dans chaque commentaire\n",
        "df['ponct'] = commentaires.apply(lambda x: x.count('!') + x.count('?') if isinstance(x, str) else 0)\n",
        "\n",
        "# Compter le nombre de mots dans chaque commentaire\n",
        "df['nb_mots'] = commentaires.apply(lambda x: count_words(x) if isinstance(x, str) else 0)\n",
        "\n",
        "# Nettoyer le texte de chaque commentaire, lemmatiser et compter la fréquence des mots\n",
        "for x in tqdm(range(0,df.shape[0])):\n",
        "    try:\n",
        "        filtered_sentence = []\n",
        "        commentaires[x] = clean_text(commentaires[x])\n",
        "        word_tokens = word_tokenize(commentaires[x], language=\"french\")\n",
        "        for w in word_tokens:\n",
        "            if not w in stop_words and w.isalpha():\n",
        "                lemma = lemmatizer.lemmatize(w)\n",
        "                filtered_sentence.append(lemma)\n",
        "        commentaires[x] = filtered_sentence\n",
        "    except:\n",
        "        commentaires[x] = \"\"\n",
        "\n",
        "\n",
        "df['Commentaire'] = commentaires\n",
        "\n",
        "\n",
        "# Créer des n-grammes de taille 2 et 3\n",
        "df['ngram_2'] = commentaires.apply(lambda x: list(ngrams(x, 2)) if isinstance(x, list) else [])\n",
        "df['ngram_3'] = commentaires.apply(lambda x: list(ngrams(x, 3)) if isinstance(x, list) else [])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eI_cwX26Qzyw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOzG_V8pQzyx"
      },
      "source": [
        "# Préparation modélisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aro2qC8GQzyy"
      },
      "outputs": [],
      "source": [
        "# Création d'une nouvelle variable \"star_cluster\" pour séparer le jeu de données en 2 segments,\n",
        "# le segment des avis positifs (=1) et le segment des avis négatifs (=0)\n",
        "df['star_cluster'] = df['star'].apply(lambda x: 1 if x >= 4 else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eViwEOoSQzyz"
      },
      "outputs": [],
      "source": [
        "# réinitialisation des compteurs\n",
        "compteur_mots_com = Counter()\n",
        "compteur_ngrams_2_com = Counter()\n",
        "compteur_ngrams_3_com = Counter()\n",
        "\n",
        "\n",
        "for x in range(0,df.shape[0]):\n",
        "    mots = df.loc[x, 'Commentaire']\n",
        "    ngrams_2 = df.loc[x, 'ngram_2']\n",
        "    ngrams_3 = df.loc[x, 'ngram_3']\n",
        "    compteur_mots_com.update(mots)\n",
        "    compteur_ngrams_2_com.update(ngrams_2)\n",
        "    compteur_ngrams_3_com.update(ngrams_3)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LmMeV1AQzy0",
        "outputId": "e9ca0f2e-1a2d-40f6-db04-eec87c57f6dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\f.rouxelin\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._update_inplace(new_data)\n"
          ]
        }
      ],
      "source": [
        "# Dichotomisation des Commentaires\n",
        "df['Commentaire'].fillna('', inplace=True)\n",
        "\n",
        "mots_cles = [mot for mot, _ in compteur_mots_com.most_common(20)] #on utilise \", _\" pour indiquer que l'on veut stocker uniquement le premier élement de 'most_common(), et non pas le compte d'apparition\n",
        "\n",
        "for mot in mots_cles:\n",
        "    df['Commentaire_'+mot] = df['Commentaire'].apply(lambda x: int(mot in x)) #int pour convertir le booléen en entier\n",
        "\n",
        "\n",
        "# Dichotomisation des ngrams2\n",
        "\n",
        "df['ngram_2'].fillna('', inplace=True)\n",
        "mots_cles = [mot for mot, _ in compteur_ngrams_2_com.most_common(20)] #on utilise \", _\" pour indiquer que l'on veut stocker uniquement le premier élement de 'most_common(), et non pas le compte d'apparition\n",
        "\n",
        "# Créer une colonne pour chaque tuples clés\n",
        "for mot in mots_cles:\n",
        "    df['ngrams_2_'+str(mot)] = df['ngram_2'].apply(lambda x: int(any(mot == t for t in x)))\n",
        "\n",
        "# Dichotomiser les ngrams2\n",
        "dummies = pd.get_dummies(df[['ngrams_2_'+str(mot) for mot in mots_cles]])\n",
        "\n",
        "# Ajouter les colonnes dichotomisées à la dataframe\n",
        "df = pd.concat([df, dummies], axis=1)\n",
        "\n",
        "\n",
        "# Dichotomisation des ngrams3\n",
        "df['ngram_3'].fillna('', inplace=True)\n",
        "mots_cles = [mot for mot, _ in compteur_ngrams_3_com.most_common(20)] #on utilise \", _\" pour indiquer que l'on veut stocker uniquement le premier élement de 'most_common(), et non pas le compte d'apparition\n",
        "\n",
        "# Créer une colonne pour chaque tuples clés\n",
        "for mot in mots_cles:\n",
        "    df['ngrams_3_'+str(mot)] = df['ngram_3'].apply(lambda x: int(any(mot == t for t in x)))\n",
        "\n",
        "# Dichotomiser les ngrams3\n",
        "dummies = pd.get_dummies(df[['ngrams_3_'+str(mot) for mot in mots_cles]])\n",
        "\n",
        "# Ajouter les colonnes dichotomisées à la dataframe\n",
        "df = pd.concat([df, dummies], axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TN75JMCvQzy2"
      },
      "outputs": [],
      "source": [
        "\n",
        "df.to_csv('commentaires_prepares.csv')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}